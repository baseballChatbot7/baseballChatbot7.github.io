---
noteId: "fb563030aa7411eba5608f6a6c3cac1f"
title:  "meeting_log_2021.05.01"
comments: false
permalink: /meeting_log/2021_05_01
---

# 2021.05.01 회의록

속죄스택: 서일 님(2), 조민정 님(1)

- 김남혁 님: 
    - 포스트를 쓰려고 했는데 일단 미뤘습니다. 민정님께 배워서 쓰겠습니다.
    - 버트는 서버 받은거에 학습시키는 중이다. 일반 위키 데이터 준비 해뒀고 종빈님 데이터 바로 합쳐서 진행할 거고, 다음주 회의 때 까지는 MRC 괜찮게 가져올 수 있을 것 같습니다.
    - 약간의 버그가 있는데, 빠르게 진행될 수 있을 것 같습니다.

- 우종빈 님: 
    - 전처리에 애를 먹고 있어서 시간을 뺃기고 있다. 끌고오면 점단위로 나누는데, 방어률에 있는 점단위로도 나눠버려서 힘들어요ㅠㅠ
        - 서일 님: 죄인이 붙겠습니다.
    - 자연어를 물어보면 정형 데이터에서 답을 가져올 수 있는 그런 트랜스포머 모델이 있다.
    - 저희 MRC 야구 전용 데이터로 만들어야 하나요?
        - 남혁 님: 야구 마스크 지문으로 프리트레인 걸고, 소수의 전용 데이터를 사용해도 될 것 같습니다.
    - 나무위키 데이터도 있다.
        - 학습에 사용하는게 좋을까요?
        - 야구에 관련된 것만?
        - 남혁 님: 일반 데이터와 도메인 데이터의 비율을 잘 잡아야할 것 같다.      
- 용준 님:
    - NER은 코엘렉트라로 진행했고, 모델 학습이 초기로 되서 뉴스 기사로 찍어봤다.
        - 생각보다는 안나오는 편이다.( 외귁인 선수 이름과 한국인 선수 이름을 외국인선수 이름을 팀명으로 주는 경우가 왕왕있다.)
    - 일반적 위키 데이터도 좋지만, 질문 데이터가 들어가는게 효율이 좋을 것 같다.
        - GPT 같은 느낌?
        - 우종빈 님: 다운스트림에서 KoQuAD로 학습할 텐데, 야구 관련된 도메인 데이터를 얼마나 늘려야 할까?
            - 김남혁 님: 결과를 보고, 데이터를 추가하는 식으로 진행하는게 효율적일 것 같습니다. 예를 들어 잘 대답 못하는 것들에 대해서 데이터를 만들어 추가학습
    - NER은 MRC를 위한 문서 검색(리-트리버) 용으로 사용할 예정입니다.
    - 우종빈 님: 누구랑 누구랑 비교를 용의하게 하는 것이 NER을 활용하면 가능할까요?
        - 최병민 님: MRC는 고게 좀 어려울 것 같습니다ㅜㅜ

- 전재열 님:
    - 챗봇 반려당해서 재신청 중이다.
    - 기여할 수 있는 부분이 명확하질 않아서.. 하차를 고민하고 있습니다...
        - 서일 님: 저도 이러케 붙여있는데 ㅠㅠ

- 최병민 님:
    - 플라스크 쪽으로 찾고, 아이디어를 검토했다.
    - 모든 문서에 대한 MRC? 처리를 해야할 것 같다. 
        - 우종빈 님: 리트리버!!!! 저희가!!!!! 지금 1등 입니다!!!!!
    - 문서 데이터를 찾을 때, 위계적으로 찾아줄 수도 있을 것 같다.
        - 아예 카테고리 형식으로 대분류 들어가고, 소분류 들어가기
            - 리트리버 사용 이전에, 카테고리를 한번 분류하기
        - 우종빈 님: 데이터가 조직적이지 않은 경우가 조금 있어서, 바로 리트리버를 사용하는 것도 같이 고려해야할 것 같다.
            - 최병민 님: 후보군을 찾아주는 건 잘 될 것 같다.
        - 김남혁 님: 해볼만 한 것 같다. 대분류 정도는 충분히 가능할 것.
    - 개요를 가지고 프리트레인하기 -> 캬 이건 논문감이다.
    - DST... 도메인 관련 대화 데이터 셋이 있어야 하는데, 구하기가 어려울 것 같습니다... 검토 하겠습니다.